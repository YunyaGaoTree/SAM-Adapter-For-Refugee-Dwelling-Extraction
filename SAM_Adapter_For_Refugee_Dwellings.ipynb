{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK5sz60nRQ25"
   },
   "source": [
    "# Segment Anything Model for Refugee-Dwelling Extraction (SAM4Refugee) From High-Resolution Satellite Imagery\n",
    "\n",
    "This notebook shows how to segment refugee dwellings from high-resolution satellite imagery using the Segment Anything Model (SAM).<br>\n",
    "\n",
    "The codes are adapted based on [SAM Adapter](https://github.com/tianrun-chen/SAM-Adapter-PyTorch) for training and [segment-geospatial](https://github.com/opengeos/segment-geospatial) for creating prediceted masks in the format of GeoTIFF and polygons in the format of ShapeFile.<br>\n",
    "\n",
    "If you use Google Colab, make sure you use GPU runtime for this notebook. Go to `Runtime` -> `Change runtime type` and select `GPU` as the hardware accelerator.For training, it is better to use A100 GPU for the sake of memory and efficiency. <br>\n",
    "\n",
    "These codes can be easily adapted for binary semantic segmentation applications in remote sensing. Feel free to use it for your own applications and implement in your local machine.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1690202510432,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "Jki_Wrpz64IG",
    "outputId": "dbdf89ba-6b0e-4e82-9fd4-e7f06c3caab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "Using device: cpu\n",
      "/home/yunya/anaconda3/envs/sam/SAM_Adapter\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9wsZ9FV7t-S"
   },
   "source": [
    "## For Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrZrHgvda9Ub"
   },
   "source": [
    "#### Train and Inference\n",
    "\n",
    "Avaialable input prompts: <br>\n",
    "- ('--config', default=\"configs/config_sam_vit_h.yaml\", help=\"use the hyperparameters provided by SAM-Adapter\")\n",
    "- ('--data', default=None, help=\"different datasets\")\n",
    "- ('--upsample', default=\"1024\", help=\"1024 or SR\") \n",
    "- ('--size', default=\"small\", help=\"small or large\") \n",
    "- ('--uptype', default=\"\", help=\"nearest bilinear EDSR\") \n",
    "- ('--epoch', default=15, help=\"epochs for training\") \n",
    "- ('--model_save_epoch', default=999, help=\"the interval of saving trained models.\") \n",
    "- ('--inference_save_epoch', default=1, help=\"the interval of saving trained models\") \n",
    "- ('--thres', default=0.5, help=\"the threshold to determine the binary map\")  \n",
    "\n",
    "`Change \"path_data\" in /run_sam/train.py & inference_noft.py & evaluation.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/train.py --data Dagaha2017 --size large --upsample 1024 \n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample 1024\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small_augmentation --upsample 1024 \n",
    "\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype nearest\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample 1024 \n",
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample SR --uptype nearest\n",
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5htzoTmRbSup"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size large \n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size small\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size noFT\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size small_augmentation \n",
    "\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample SR --size small --uptype nearest\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample SR --size small --uptype bilinear\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample SR --size small --uptype EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
