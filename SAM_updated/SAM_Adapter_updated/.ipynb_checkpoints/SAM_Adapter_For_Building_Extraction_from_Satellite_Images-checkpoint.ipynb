{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK5sz60nRQ25"
   },
   "source": [
    "# Segment Anything Model for Building Extraction From High-Resolution Satellite Imagery\n",
    "\n",
    "This notebook shows how to extract buildings within refugee/IDP settlements (or buildings in general) from high-resolution satellite imagery using the Segment Anything Model (SAM) Adapter.<br>\n",
    "\n",
    "The codes are adapted based on [SAM Adapter](https://github.com/tianrun-chen/SAM-Adapter-PyTorch) for training and [segment-geospatial](https://github.com/opengeos/segment-geospatial) for creating prediceted masks in the format of GeoTIFF and polygons in the format of ShapeFile.<br>\n",
    "\n",
    "If you use Google Colab, make sure you use GPU runtime for this notebook. Go to `Runtime` -> `Change runtime type` and select `GPU` as the hardware accelerator.For training, it is better to use A100 GPU for the sake of memory and efficiency. <br>\n",
    "\n",
    "These codes can be easily adapted for binary semantic segmentation applications in remote sensing. Feel free to use it for your own applications and implement in your local machine.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1468,
     "status": "ok",
     "timestamp": 1702285648780,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "Zhw5Jxeq_y5S",
    "outputId": "a5178ba6-4eed-4aef-e08d-c7abf46073a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yunya/anaconda3/envs/SAM_Adapter\n",
      "2.1.0.post301\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import pathlib\n",
    "\n",
    "# set up working directory and data folder\n",
    "# path_base = \"/content/drive/MyDrive/PhD_Research/SAM/SAM_Adapter_Final_4_Codes\"\n",
    "# os.chdir(path_base)\n",
    "path = os.getcwd() # your current working directory where your codes are stored.\n",
    "print(path)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9wsZ9FV7t-S"
   },
   "source": [
    "## For Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrZrHgvda9Ub"
   },
   "source": [
    "#### Train and Inference\n",
    "\n",
    "Avaialable input prompts: <br>\n",
    "- parser = argparse.ArgumentParser()\n",
    "- parser.add_argument('--config', default=\"configs/config_sam_vit_h.yaml\", help=\"use the hyperparameters provided by SAM-Adapter\")\n",
    "- parser.add_argument('--data', default=None, help=\"different datasets\")\n",
    "- parser.add_argument('--upsample', default=\"1024\", help=\"1024 or upscaled\") \n",
    "- parser.add_argument('--size', default=\"small\", help=\"small or large\") \n",
    "- parser.add_argument('--uptype', default=\"\", help=\"cubic or SR\") \n",
    "- parser.add_argument('--epoch', default=10, help=\"epochs for training\") \n",
    "- parser.add_argument('--model_save_epoch', default=2, help=\"the interval of saving trained models, do not save models in default due to big size of model.\") \n",
    "- parser.add_argument('--inference_save_epoch', default=1, help=\"the interval of saving trained models\") \n",
    "- parser.add_argument('--thres', default=0.5, help=\"the threshold to determine the binary map\") \n",
    "\n",
    "`Change \"path_data\" in /run_sam/train.py & inference_noft.py & evaluation.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88724,
     "status": "ok",
     "timestamp": 1702000658635,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "RxKdj2TZAcpU",
    "outputId": "18ea15b8-723b-455d-a13a-122897f513f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yunya/anaconda3/envs/process_data_sam/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "ipynb_checkpoints folder not found.\n",
      "config saved.\n",
      "train dataset: size=11\n",
      "  inp: shape=(3, 1024, 1024)\n",
      "  gt: shape=(1, 1024, 1024)\n",
      "model: #params=641.3M\n",
      "model_grad_params:4245556 \n",
      "model_total_params:641271604\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n"
     ]
    }
   ],
   "source": [
    "# command example1\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --epoch 3 --model_save_epoch 1 --inference_save_epoch 1 --size small --upsample 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yunya/anaconda3/envs/process_data_sam/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "ipynb_checkpoints folder not found.\n",
      "config saved.\n",
      "train dataset: size=11\n",
      "  inp: shape=(3, 1024, 1024)\n",
      "  gt: shape=(1, 1024, 1024)\n",
      "model: #params=641.3M\n",
      "model_grad_params:4245556 \n",
      "model_total_params:641271604\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "^C\n",
      "[2023-12-18 13:16:37,568] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
      "[2023-12-18 13:16:37,568] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 2835760 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yunya/anaconda3/envs/SAM_Adapter/run_sam/train.py\", line 331, in <module>\n",
      "    main(config, path_output, path_model, model_save_epoch, inference_save_epoch, thres, upsample, path_test_img_list, path_test_gt_list)\n",
      "  File \"/home/yunya/anaconda3/envs/SAM_Adapter/run_sam/train.py\", line 257, in main\n",
      "    inference_main(model, config, thres, path_output_pred, upsample, path_test_img_list, path_test_gt_list)\n",
      "  File \"/home/yunya/anaconda3/envs/SAM_Adapter/run_sam/inference_ft.py\", line 247, in inference_main\n",
      "    prob_mask = inference_image(image, model)\n",
      "  File \"/home/yunya/anaconda3/envs/SAM_Adapter/run_sam/inference_ft.py\", line 151, in inference_image\n",
      "    mask_pred = mask_pred.cpu().numpy().copy()[0,0]\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# command example2\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --epoch 3 --model_save_epoch 1 --size small --upsample upscaled --uptype cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference based on pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yunya/anaconda3/envs/process_data_sam/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "config saved.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n"
     ]
    }
   ],
   "source": [
    "!torchrun run_sam/inference_ft.py --data Dagaha2017 --model_save_epoch 1 --size small --upsample upscaled --uptype cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5htzoTmRbSup"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xfjRZjOo8Y57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.0\n",
      "precision: 0.0\n",
      "f1: 0.0\n",
      "iou: 0.0\n"
     ]
    }
   ],
   "source": [
    "from evaluation import evaluation_single_main\n",
    "\n",
    "# select a specific prediction result and ground truth data to be evaluated\n",
    "# this part can be furthur automated based on needs\n",
    "path_gt = \"/home/yunya/anaconda3/envs/Data/Dagaha2017/SAM/upscaled/test/cubic/gt/dagahaley2.tif\"\n",
    "path_pred = \"/home/yunya/anaconda3/envs/SAM_Adapter/outputs/Dagaha2017/small/upscaled/cubic/epoch2/area2/pred_mask_bin0.5.tif\"\n",
    "\n",
    "evaluation_result = evaluation_single_main(path_pred, path_gt)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
