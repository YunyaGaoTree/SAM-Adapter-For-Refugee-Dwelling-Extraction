{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XxpwtnhDNzu"
   },
   "source": [
    "# Data preparation\n",
    "\n",
    "- This notebook includes data preprocessing steps for [SAM-Adapter](https://github.com/tianrun-chen/SAM-Adapter-PyTorch).\n",
    "- The codes mainly source from [HiSup](https://github.com/SarahwXU/HiSup).\n",
    "- This workflow is only suitable for ***binary segmentation***. Feel free to adapt it for multiclass segmentation.\n",
    "- You can upscale images (4 times) by a super resolution model ([EDSR](https://github.com/aswintechguy/Deep-Learning-Projects/tree/main/Super%20Resolution%20-%20OpenCV)) by OpenCV.\n",
    "- The default structure and format of your input datasets are:<br>\n",
    "Here we aim to convert a large geotiff image/label data into small patches for deep learning models.<br>\n",
    "\n",
    "- **Data Structure:** <br>\n",
    "\n",
    "    Dataset1<br>\n",
    "    - raw\n",
    "        - train\n",
    "            - images  (geotiff, uint8, 3 bands (RGB), you can create and enhance image data in GIS software in advance)\n",
    "            - gt      (geotiff, uint8, value:0(background), 255(targets)(not necessary to have to be 255 if it is a binary segmentation but have to be distinctive from background))\n",
    "        - test\n",
    "            - images\n",
    "            - gt\n",
    "    \n",
    "    Dataset2<br>\n",
    "        ... ...<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1702284057764,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "7xRfQvNeHfoc",
    "outputId": "12d861b7-357e-4240-abdb-7d214a9bcf49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yunya/anaconda3/envs/Data_Preparation/Data_Preparation_Final\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# your current working directory where your codes are stored.\n",
    "path = os.getcwd() \n",
    "print(path)\n",
    "\n",
    "# if path is not expected, then unnote these two lines to customize the rigth working directory\n",
    "# path_base = \"/content/drive/MyDrive/PhD_Research/SAM/Data_Final/Data_Preparation/Data_Preparation_Final\"\n",
    "# os.chdir(path_base)\n",
    "\n",
    "# set up the path for datasets\n",
    "path_database = \"/home/yunya/anaconda3/envs/Data\"\n",
    "\n",
    "# import self-defined functions\n",
    "from DataProcessing import data_process_sam_seg_final, data_process_augmentation_final\n",
    "from DataProcessing import upscale_data_by_SR_final, upscale_data_by_cubic_final\n",
    "from DataProcessing import upscale_testing_image_by_SR_final, upscale_testing_data_cubic_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf7rB187DNz3"
   },
   "source": [
    "## Data preparation for SAM Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps you have multiple datasets to be processed. print them then select the datasets you would like to process.\n",
    "os.listdir(path_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1702283762039,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "xXitaQhOM4zP"
   },
   "outputs": [],
   "source": [
    "# set up datasets in list format to be processed\n",
    "data_list = ['Dagaha2017', \"Djibo2019\"]\n",
    "\n",
    "# for type_list, the naming rule is \"train_\" plus a short description.\n",
    "# it is set because you may want to try different training datasets\n",
    "# for example here, I want to compare the influence of data size on model performance, I set train_small and train_large.\n",
    "# in training data folder, you can put multiple geotiff data of images and ground truth data\n",
    "type_list = ['train_small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43656,
     "status": "ok",
     "timestamp": 1702283805690,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "ssgM-M8ADNz4",
    "outputId": "a2812c8f-cd22-4cc9-9b11-2d4ad954a962",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing: Dagaha2017 train_small 1024\n",
      "Start processing: Djibo2019 train_small 1024\n"
     ]
    }
   ],
   "source": [
    "# 1024 is the default patchsize for SAM adapter.\n",
    "# however, when you create patches with 1024 by 1024 pixels, you will observe that there are many small buildings in one single patch, which can bring difficulty for training\n",
    "patch_size = 1024\n",
    "\n",
    "data_process_sam_seg_final(path_database, data_list, type_list, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14038,
     "status": "ok",
     "timestamp": 1702283819719,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "AbFZaWz9DNz5",
    "outputId": "7a0a3ecd-d92e-49e4-993f-601b2e41f30b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing: Dagaha2017 train_small 256\n",
      "Start processing: Djibo2019 train_small 256\n"
     ]
    }
   ],
   "source": [
    "# 256 is selected to create smaller patches that can be upscaled to 1024 by EDSR or other \"bilinear/cubic\" approaches.\n",
    "# you can choose other sizes for upscaling by bicubic interpretation but 256 is fixed for EDSR.\n",
    "patch_size = 256\n",
    "\n",
    "data_process_sam_seg_final(path_database, data_list, type_list, patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FDt_hvLDNz6"
   },
   "source": [
    "## Data augmentation by flipping and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1702283819720,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "DTfy9CsdDNz6"
   },
   "outputs": [],
   "source": [
    "# set up datasets to be used\n",
    "data_list = ['Dagaha2017']\n",
    "type_list = ['train_small']\n",
    "\n",
    "# data augmentation should be chosen when the size of training data is too small to produce satisifying results\n",
    "# select all or some of the following data augmentation choices\n",
    "# operation_list = [\"vertical_flip\", \"horizontal_flip\", \"rotate\"]\n",
    "# degrees_list = [90, 180, 270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124633,
     "status": "ok",
     "timestamp": 1702283945258,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "UuQe7IGjDNz8",
    "outputId": "b19a313d-62a1-4abb-fa5a-ed0ff0dd34a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing: /home/yunya/anaconda3/envs/Data/Dagaha2017/SAM/1024\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "patch_size = 1024\n",
    "operation_list = [\"vertical_flip\", \"rotate\"]\n",
    "degrees_list = [90, 180]\n",
    "# if you want to test the influences of different data augmentation combinations\n",
    "# set \"aug_idx\" as other values, such as 1, 2... or _flip_rot40 （_ is necessary to output folder more readable）\n",
    "aug_idx = \"\"\n",
    "\n",
    "data_process_augmentation_final(path_database, data_list, type_list, patch_size, operation_list, degrees_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22500,
     "status": "ok",
     "timestamp": 1702283967753,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "HOzBoKkXVvPH",
    "outputId": "8dfd2549-b185-4c21-b6d1-0d03e12e8131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing: /home/yunya/anaconda3/envs/Data/Dagaha2017/SAM/256\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "patch_size = 256\n",
    "operation_list = [\"vertical_flip\", \"rotate\"]\n",
    "degrees_list = [90, 180]\n",
    "# if you want to test more, set \"aug_idx\" as other values, such as 1, 2... or _flip_rot40 （_ is necessary to output folder more readable）\n",
    "aug_idx = \"\"\n",
    "\n",
    "data_process_augmentation_final(path_database, data_list, type_list, patch_size, operation_list, degrees_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsqj9nSoDNz8"
   },
   "source": [
    "## Upscale image of training data (optional) \n",
    "The upscaling by SR may **take quite a long time**, but it can generate better results in most experiments. <br>\n",
    "It is much faster to use traditional upscaling approaches (cubic interpolation here).<br>\n",
    "**Therefore, cubic interpolation is recommended.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702283967754,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "ztqtGfMQFk8f"
   },
   "outputs": [],
   "source": [
    "data_list = ['Dagaha2017']\n",
    "type_list = ['train_small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtBUH0PIDNz8"
   },
   "outputs": [],
   "source": [
    "# upscale by SR model - EDSR model (better results, but very slow)\n",
    "upscale_data_by_SR_final(path_database, data_list, type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68179,
     "status": "ok",
     "timestamp": 1702284035926,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "OLkbcG4ZFmVM",
    "outputId": "a08de278-162b-4001-81be-2035736bc73e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing: Dagaha2017    train_small\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# upscale by cubic interpolation (faster, recommended)\n",
    "upscale_data_by_cubic_final(path_database, data_list, type_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYLKQSBtDNz9"
   },
   "source": [
    "## Upscale testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1702284082611,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "P89b0owlIWz5"
   },
   "outputs": [],
   "source": [
    "data_list = ['Dagaha2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16396,
     "status": "ok",
     "timestamp": 1702284100846,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "fWKftHPBDNz9",
    "outputId": "37948f1c-248d-416d-d1d6-a3daa0b037ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing by cubic: /home/yunya/anaconda3/envs/Data/Dagaha2017/raw/test/images/dagahaley1.tif\n",
      "(3, 12404, 19132)\n",
      "Processing by cubic: /home/yunya/anaconda3/envs/Data/Dagaha2017/raw/test/images/dagahaley2.tif\n",
      "(3, 5496, 5556)\n"
     ]
    }
   ],
   "source": [
    "#### upscale data by cubic interpolation (recommended, faster), if you want to try nearest or bilinear, change them in the .py script\n",
    "data_type = \"images\"\n",
    "patch_size = 256\n",
    "\n",
    "for dataset in data_list:\n",
    "    upscale_testing_data_cubic_final(path_database, dataset, data_type, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3951,
     "status": "ok",
     "timestamp": 1702284104780,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -60
    },
    "id": "Qft7ueBmDNz9",
    "outputId": "f073b144-632a-4336-d15c-226b19e9bae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing by cubic: /home/yunya/anaconda3/envs/Data/Dagaha2017/raw/test/gt/dagahaley1.tif\n",
      "(1, 12408, 19128)\n",
      "Processing by cubic: /home/yunya/anaconda3/envs/Data/Dagaha2017/raw/test/gt/dagahaley2.tif\n",
      "(1, 5492, 5556)\n"
     ]
    }
   ],
   "source": [
    "# upscale Ground Truth data\n",
    "data_type = \"gt\"\n",
    "patch_size = 256\n",
    "\n",
    "for dataset in data_list:\n",
    "    upscale_testing_data_cubic_final(path_database, dataset, data_type, patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYZoGKVFDNz9",
    "outputId": "f37ca32c-a4bb-4900-efa3-e66a0d6a1b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing by SR: /home/yunya/anaconda3/envs/Data/Dagaha2017/raw/test/images/dagahaley2.tif\n",
      "num_patches_height: 3, num_patches_width: 3\n",
      "Done:    Row: 0\n",
      "Done:    Row: 1\n",
      "Done:    Row: 2\n",
      "Processing by SR: /home/yunya/anaconda3/envs/Data/Dagaha2017/raw/test/images/dagahaley1.tif\n",
      "num_patches_height: 7, num_patches_width: 10\n"
     ]
    }
   ],
   "source": [
    "#### upscale image by SR (very slow)\n",
    "data_list = ['Dagaha2017']\n",
    "data_type = \"images\"\n",
    "\n",
    "for dataset in data_list:\n",
    "    upscale_testing_image_by_SR_final(path_database, dataset, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "data_sam (3.10)",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
