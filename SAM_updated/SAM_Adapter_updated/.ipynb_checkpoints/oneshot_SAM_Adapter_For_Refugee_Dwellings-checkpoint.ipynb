{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK5sz60nRQ25"
   },
   "source": [
    "# Segment Anything Model for Refugee-Dwelling Extraction (SAM4Refugee) From High-Resolution Satellite Imagery\n",
    "\n",
    "This notebook shows how to segment refugee dwellings from high-resolution satellite imagery using the Segment Anything Model (SAM).<br>\n",
    "\n",
    "The codes are adapted based on [SAM Adapter](https://github.com/tianrun-chen/SAM-Adapter-PyTorch) for training and [segment-geospatial](https://github.com/opengeos/segment-geospatial) for creating prediceted masks in the format of GeoTIFF and polygons in the format of ShapeFile.<br>\n",
    "\n",
    "If you use Google Colab, make sure you use GPU runtime for this notebook. Go to `Runtime` -> `Change runtime type` and select `GPU` as the hardware accelerator.For training, it is better to use A100 GPU for the sake of memory and efficiency. <br>\n",
    "\n",
    "These codes can be easily adapted for binary semantic segmentation applications in remote sensing. Feel free to use it for your own applications and implement in your local machine.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1690202510432,
     "user": {
      "displayName": "Yunya Gao",
      "userId": "05443726764578958815"
     },
     "user_tz": -120
    },
    "id": "Jki_Wrpz64IG",
    "outputId": "dbdf89ba-6b0e-4e82-9fd4-e7f06c3caab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "Using device: cpu\n",
      "/home/yunya/anaconda3/envs/sam/SAM_Adapter\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9wsZ9FV7t-S"
   },
   "source": [
    "## For Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrZrHgvda9Ub"
   },
   "source": [
    "#### Train and Inference\n",
    "\n",
    "Avaialable input prompts: <br>\n",
    "- ('--config', default=\"configs/config_sam_vit_h.yaml\", help=\"use the hyperparameters provided by SAM-Adapter\")\n",
    "- ('--data', default=None, help=\"different datasets\")\n",
    "- ('--upsample', default=\"1024\", help=\"1024 or SR\") \n",
    "- ('--size', default=\"small\", help=\"small or large\") \n",
    "- ('--uptype', default=\"\", help=\"nearest bilinear EDSR\") \n",
    "- ('--epoch', default=15, help=\"epochs for training\") \n",
    "- ('--model_save_epoch', default=999, help=\"the interval of saving trained models.\") \n",
    "- ('--inference_save_epoch', default=1, help=\"the interval of saving trained models\") \n",
    "- ('--thres', default=0.5, help=\"the threshold to determine the binary map\")  \n",
    "\n",
    "`Change \"path_data\" in /run_sam/train.py & inference_noft.py & evaluation.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun run_sam/train.py --data Dagaha2017 --size large --upsample 1024 \n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample 1024\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small_augmentation --upsample 1024 \n",
    "\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype nearest\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/train.py --data Minawao2017 --size large --upsample 1024 \n",
    "!torchrun run_sam/train.py --data Minawao2017 --size small --upsample 1024\n",
    "!torchrun run_sam/train.py --data Minawao2017 --size small_augmentation --upsample 1024 \n",
    "\n",
    "!torchrun run_sam/train.py --data Minawao2017 --size small --upsample SR --uptype nearest\n",
    "!torchrun run_sam/train.py --data Minawao2017 --size small --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/train.py --data Minawao2017 --size small --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun run_sam/train.py --data Dagaha2017 --size large --upsample 1024 \n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample 1024\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small_augmentation --upsample 1024 \n",
    "\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype nearest\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/train.py --data Dagaha2017 --size large --upsample 1024 \n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample 1024\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small_augmentation --upsample 1024 \n",
    "\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype nearest\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/train.py --data Dagaha2017 --size small --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample 1024 \n",
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample SR --uptype nearest\n",
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample SR --uptype bilinear\n",
    "!torchrun run_sam/inference_noft.py --data Dagaha2017 --upsample SR --uptype EDSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5htzoTmRbSup"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size large \n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size small\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size noFT\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample 1024 --size small_augmentation \n",
    "\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample SR --size small --uptype nearest\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample SR --size small --uptype bilinear\n",
    "!torchrun run_sam/evaluation.py --data Dagaha2017 --upsample SR --size small --uptype EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minawao2017 Dagaha2017 Djibo2019 Kutupalong2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yunya/anaconda3/envs/sam/lib/python3.11/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "ipynb_checkpoints folder not found.\n",
      "config saved.\n",
      "train dataset: size=1\n",
      "  inp: shape=(3, 1024, 1024)\n",
      "  gt: shape=(1, 1024, 1024)\n",
      "val dataset: size=7\n",
      "  inp: shape=(3, 1024, 1024)\n",
      "  gt: shape=(1, 1024, 1024)\n",
      "model: #params=641.3M\n",
      "model_grad_params:4245556 \n",
      "model_total_params:641271604\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "/home/yunya/anaconda3/envs/sam/SAM_Adapter/run_sam/inference_ft.py:174: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(50, 50))\n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "Predicted probability map.                                                      \n",
      "Save predicted probability map, binary map with threshold at 0.5 and shapefile.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "!torchrun run_sam/train.py --data Dagaha2017 --size oneshot --upsample 1024 --epoch 50 --inference_save_epoch 5\n",
    "!torchrun run_sam/train.py --data Minawao2017 --size oneshot --upsample 1024 --epoch 50 --inference_save_epoch 5\n",
    "!torchrun run_sam/train.py --data Djibo2019 --size oneshot --upsample 1024 --epoch 50 --inference_save_epoch 5\n",
    "!torchrun run_sam/train.py --data Kutupalong2018 --size oneshot --upsample 1024 --epoch 50 --inference_save_epoch 5\n",
    "!torchrun run_sam/train.py --data Nduta2017 --size oneshot --upsample 1024 --epoch 50 --inference_save_epoch 5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
